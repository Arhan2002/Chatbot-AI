{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google text to speech library used to translate text to speech\n",
    "!pip install gTTs \n",
    "!pip install English-to-Hindi\n",
    "!pip install translate\n",
    "!pip install SpeechRecognition\n",
    "!pip install pipwin\n",
    "!pipwin install PyAudio\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "#nltk is library used for provide some set of algorithms for nlp\n",
    "#It contains text processing libraries for tokenization, classification and tagging.\n",
    "#natural language toolkit\n",
    "import nltk \n",
    "#stopwords are the words that you donot want to use to describe the topic.\n",
    "from nltk.corpus import stopwords\n",
    "###########################\n",
    "import numpy as np\n",
    "from gtts import gTTS\n",
    "#provides for useful shell environment to execute python code\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "###########################\n",
    "\n",
    "import json\n",
    "import random\n",
    "from nltk.tag import pos_tag # for proper noun\n",
    "#Tokenization means splitting up a larger body of text into smaller lines, words or even creating words \n",
    "#for a non-English language.\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "#stem is basically used to reduce the words to the root word\n",
    "#Lemmatizer is similar to stemming but it group together words and bring context to it.\n",
    "#It basically links words of similar meanings to one word.\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "filename=\"intents.json\"\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "intents = json.loads(open(filename).read())\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "print(intents)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "words=[]\n",
    "classes=[]\n",
    "documents=[]\n",
    "ignore_letters = ['!', '?', ',', '.',';',':']\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopWords = list(set(stopwords.words(\"english\")))\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        word_list = nltk.word_tokenize(pattern)\n",
    "        word_list=[lemmatizer.lemmatize(word.lower()) for word in word_list if word not in stopWords and word not in ignore_letters ]\n",
    "        words.extend(word_list)\n",
    "        # print(word_list)\n",
    "        documents.append((word_list,intent['tag']))\n",
    "        if intent['tag'].lower() not in classes:\n",
    "            classes.append(intent['tag'].lower())\n",
    "print(documents)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "words = sorted(set(words))\n",
    "classes = sorted(set(classes))\n",
    "print(documents)\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "from translate import Translator\n",
    "print(\"HEY I AM QBOT! \")\n",
    "print(\"How you want to give the input?(audio or text)\")\n",
    "print(\"HOW CAN I HELP YOU?\")\n",
    "into = \"HEY I AM Q BOT! How you want to give the input? \"\n",
    "translator= Translator(to_lang=\"Hindi\")\n",
    "translation = translator.translate(into)\n",
    "print (translation)\n",
    "audio = gTTS(translation)\n",
    "audio = gTTS(into)\n",
    "audio.save('2.wav')\n",
    "sound_file = '2.wav'\n",
    "\n",
    "#from translate import Translator\n",
    "#translator= Translator(to_lang=\"Hindi\")\n",
    "#translation = translator.translate(into)\n",
    "#print (translation)\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "Audio('2.wav',rate=44100,autoplay = True)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import speech_recognition as s_r\n",
    "a=[]\n",
    "print(s_r.__version__) # just to print the version not required\n",
    "r = s_r.Recognizer()\n",
    "my_mic = s_r.Microphone(device_index=1) #my device index is 1, you have to put your device index\n",
    "with my_mic as source:\n",
    "    print(\"Say now!!!!\")\n",
    "    audio = r.listen(source) #take voice input from the microphone\n",
    "    a.append(r.recognize_google(audio))\n",
    "print(r.recognize_google(audio)) \n",
    "\n",
    "#a=input(\"How you want to give the input?(audio or text)\")\n",
    "#audio = gTTS(\"How you want to give the input?(audio or text)\")\n",
    "#audio = gTTS(a)\n",
    "#audio.save('2.wav')\n",
    "#sound_file = '2.wav'\n",
    "for i in a:\n",
    "    if i==\"audio\":\n",
    "        c=[]\n",
    "        print(s_r.__version__) # just to print the version not required\n",
    "        r = s_r.Recognizer()\n",
    "        my_mic = s_r.Microphone(device_index=1) #my device index is 1, you have to put your device index\n",
    "        with my_mic as source:\n",
    "            print(\"What you want to ask? SAY NOW!!!!\")\n",
    "            audio = r.listen(source) #take voice input from the microphone\n",
    "            c.append(r.recognize_google(audio))\n",
    "        print(r.recognize_google(audio)) \n",
    "#print(c)\n",
    "        for i in c:\n",
    "            p=nltk.word_tokenize(i)\n",
    "            p=[lemmatizer.lemmatize(word.lower()) for word in p if word not in stopWords and word not in ignore_letters ]\n",
    "            print(p)\n",
    "#c=nltk.word_tokenize(c)\n",
    "#c=[lemmatizer.lemmatize(word.lower()) for word in c if word not in stopWords and word not in ignore_letters ]\n",
    "        print(c)\n",
    "    elif i==\"text\":\n",
    "        chat=input()\n",
    "        p=nltk.word_tokenize(chat)\n",
    "        p=[lemmatizer.lemmatize(word.lower()) for word in p if word not in stopWords and word not in ignore_letters ]\n",
    "        print(p)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "final_tag={}\n",
    "for tag in classes:\n",
    "  final_tag[tag]=0\n",
    "print(final_tag)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "for doc in documents:\n",
    "  for i in p:\n",
    "    for que in doc[0]:\n",
    "      if i==que:\n",
    "        # print(doc[1])\n",
    "        final_tag[doc[1].lower()]+=1\n",
    "print(final_tag)\n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "select_tag=max(final_tag,key=final_tag.get)\n",
    "# print(max(final_tag,key=final_tag.get))\n",
    "if final_tag.get(select_tag) == None or final_tag.get(select_tag) == 0:\n",
    "  select_tag = 'default'\n",
    "# else:\n",
    "#   select_tag='default'\n",
    "print(select_tag)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "ansList=[]\n",
    "for intent in intents['intents']:\n",
    "  if intent['tag'].lower()==select_tag:\n",
    "    for response in intent['responses']:\n",
    "      ansList.append(response)\n",
    "      # print(response)\n",
    "      result=random.choice(ansList)\n",
    "audio = gTTS(result)\n",
    "audio.save('1.wav')\n",
    "sound_file = '1.wav'\n",
    "# Audio(sound_file,rate=\"framerate\")\n",
    "# IPython.display.Audio('1.wav')\n",
    "# Audio('1.wav',rate=44100)\n",
    "print(result)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Audio('1.wav',rate=600000,autoplay = True)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
